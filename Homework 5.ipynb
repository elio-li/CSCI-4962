{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Homework 5**\n\nIn your project, you will pick an image dataset to solve a classification task. Provide a link to your dataset.\n\nPokemon Image Dataset: https://www.kaggle.com/vishalsubbiah/pokemon-images-and-types?select=images","metadata":{}},{"cell_type":"markdown","source":"## **Task 1**","metadata":{}},{"cell_type":"markdown","source":"### **Pre-Setup**\n\nI'd like to find out each pokemons primary type(fire, water, grass etc.) based on their image.","metadata":{}},{"cell_type":"code","source":"# Imports\nimport pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport matplotlib.gridspec as gridspec\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-11-06T03:43:21.386094Z","iopub.execute_input":"2021-11-06T03:43:21.386397Z","iopub.status.idle":"2021-11-06T03:43:21.391738Z","shell.execute_reply.started":"2021-11-06T03:43:21.386364Z","shell.execute_reply":"2021-11-06T03:43:21.390954Z"},"trusted":true},"execution_count":253,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras as ks\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, Activation, BatchNormalization","metadata":{"execution":{"iopub.status.busy":"2021-11-06T03:43:24.467299Z","iopub.execute_input":"2021-11-06T03:43:24.467604Z","iopub.status.idle":"2021-11-06T03:43:24.473027Z","shell.execute_reply.started":"2021-11-06T03:43:24.467570Z","shell.execute_reply":"2021-11-06T03:43:24.471969Z"},"trusted":true},"execution_count":254,"outputs":[]},{"cell_type":"code","source":"# Get CSV Data\ndf = pd.read_csv(\"../input/pokemon-images-and-types/pokemon.csv\")\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T03:46:02.522198Z","iopub.execute_input":"2021-11-06T03:46:02.522629Z","iopub.status.idle":"2021-11-06T03:46:02.539550Z","shell.execute_reply.started":"2021-11-06T03:46:02.522598Z","shell.execute_reply":"2021-11-06T03:46:02.538853Z"},"trusted":true},"execution_count":274,"outputs":[]},{"cell_type":"code","source":"# Select only a few types of pokemon because data are too little\nselected = [\"Water\", \"Fire\", \"Grass\"]\n\ndf = df[df['Type1'].isin(selected)]\ndf['Type1'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-06T03:46:05.348466Z","iopub.execute_input":"2021-11-06T03:46:05.348777Z","iopub.status.idle":"2021-11-06T03:46:05.359206Z","shell.execute_reply.started":"2021-11-06T03:46:05.348738Z","shell.execute_reply":"2021-11-06T03:46:05.358091Z"},"trusted":true},"execution_count":275,"outputs":[]},{"cell_type":"code","source":"img = os.listdir('../input/pokemon-images-and-types/images/images/')\nfor i in img:\n  name = i.split('.')[0]\n  df.loc[df['Name'] == name, [\"Image\"]] = i\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T03:46:07.571616Z","iopub.execute_input":"2021-11-06T03:46:07.572125Z","iopub.status.idle":"2021-11-06T03:46:08.550198Z","shell.execute_reply.started":"2021-11-06T03:46:07.572072Z","shell.execute_reply":"2021-11-06T03:46:08.549143Z"},"trusted":true},"execution_count":276,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.rmtree('train/')\nshutil.rmtree('test/')\nshutil.rmtree('valid/')\n\nos.mkdir('train/')\nos.mkdir('test/')\nos.mkdir('valid/')\n\nfor i in df['Type1'].unique():\n  os.mkdir('train/'+str(i)+'/')\n  os.mkdir('test/'+str(i)+'/')\n  os.mkdir('valid/'+str(i)+'/')","metadata":{"execution":{"iopub.status.busy":"2021-11-06T03:46:09.997326Z","iopub.execute_input":"2021-11-06T03:46:09.997772Z","iopub.status.idle":"2021-11-06T03:46:10.023182Z","shell.execute_reply.started":"2021-11-06T03:46:09.997721Z","shell.execute_reply":"2021-11-06T03:46:10.021532Z"},"trusted":true},"execution_count":277,"outputs":[]},{"cell_type":"code","source":"x_train, x_rem, y_train, y_rem = train_test_split(df, df[\"Type1\"], train_size=0.7)\nx_valid, x_test, y_valid, y_test = train_test_split(x_rem, y_rem, test_size=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T03:46:12.646524Z","iopub.execute_input":"2021-11-06T03:46:12.646807Z","iopub.status.idle":"2021-11-06T03:46:12.654344Z","shell.execute_reply.started":"2021-11-06T03:46:12.646779Z","shell.execute_reply":"2021-11-06T03:46:12.653351Z"},"trusted":true},"execution_count":278,"outputs":[]},{"cell_type":"code","source":"from shutil import copyfile, copy2\nfor image, types in zip(\"../input/pokemon-images-and-types/images/images/\" + x_train['Image'], y_train):\n  copy2(image, 'train/' + types)\nfor image, types in zip(\"../input/pokemon-images-and-types/images/images/\" + x_test['Image'], y_test):\n  copy2(image, 'test/' + types)\nfor image, types in zip(\"../input/pokemon-images-and-types/images/images/\" + x_valid['Image'], y_valid):\n  copy2(image, 'valid/' + types)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T03:46:18.262681Z","iopub.execute_input":"2021-11-06T03:46:18.263295Z","iopub.status.idle":"2021-11-06T03:46:18.518239Z","shell.execute_reply.started":"2021-11-06T03:46:18.263241Z","shell.execute_reply":"2021-11-06T03:46:18.517362Z"},"trusted":true},"execution_count":280,"outputs":[]},{"cell_type":"code","source":"train = ImageDataGenerator().flow_from_directory('train/')\ntest = ImageDataGenerator().flow_from_directory('test/')\nval = ImageDataGenerator().flow_from_directory('valid/')","metadata":{"execution":{"iopub.status.busy":"2021-11-06T03:46:21.234164Z","iopub.execute_input":"2021-11-06T03:46:21.234532Z","iopub.status.idle":"2021-11-06T03:46:21.548779Z","shell.execute_reply.started":"2021-11-06T03:46:21.234498Z","shell.execute_reply":"2021-11-06T03:46:21.547143Z"},"trusted":true},"execution_count":281,"outputs":[]},{"cell_type":"markdown","source":"**Part 1 (20 points):** This step involves downloading, preparing, and visualizing your dataset. Create a convolutional base using a common pattern: a stack of Conv and MaxPooling layers. Depending on the problem and the dataset you must decide what pattern you want to use (i.e., how many Conv layers and how many pooling layers). Please describe why you chose a particular pattern. Add the final dense layer(s). Compile and train the model. Report the final evaluation and describe the metrics.\n\n---\n\nFor the first Conv2D I choosed 16 filters with size 3, the activation function for each Conv2D is relu. To reduce the spatial dimensions of the output volume a MaxPooling2D is used where the size is 3. For the third layer a dropout of 30% is used to prevent overfitting. After that add the 2nd, 3rd convolutional layer and increase the filter gradually. Lastly flatten into 1 dimension and a dense layer.","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(16, (3, 3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (3, 3)))\n\nmodel.add(Conv2D(32, (3, 3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (3, 3)))\n\nmodel.add(Conv2D(64, (3, 3), activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size = (3, 3)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(3, activation = 'softmax'))\nmodel.compile(loss = 'mean_squared_error', optimizer = \"adam\", metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-11-06T03:46:24.039651Z","iopub.execute_input":"2021-11-06T03:46:24.039984Z","iopub.status.idle":"2021-11-06T03:46:24.073935Z","shell.execute_reply.started":"2021-11-06T03:46:24.039952Z","shell.execute_reply":"2021-11-06T03:46:24.073132Z"},"trusted":true},"execution_count":282,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train, epochs = 20, validation_data = val)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T03:46:36.312059Z","iopub.execute_input":"2021-11-06T03:46:36.314276Z","iopub.status.idle":"2021-11-06T03:47:04.903461Z","shell.execute_reply.started":"2021-11-06T03:46:36.314231Z","shell.execute_reply":"2021-11-06T03:47:04.902662Z"},"trusted":true},"execution_count":284,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\npredict = model.predict(test)\ny_pred = np.argmax(predict, axis=-1)\n\ny_pred_conv = []\nfor i in y_pred:\n  if i == 0:\n    y_pred_conv.append(\"Fire\")\n  elif i == 1:\n    y_pred_conv.append(\"Grass\")\n  elif i == 2:\n    y_pred_conv.append(\"Water\")\n\nprint(classification_report(y_test, y_pred_conv))","metadata":{"execution":{"iopub.status.busy":"2021-11-06T03:47:48.628354Z","iopub.execute_input":"2021-11-06T03:47:48.628641Z","iopub.status.idle":"2021-11-06T03:47:48.850055Z","shell.execute_reply.started":"2021-11-06T03:47:48.628612Z","shell.execute_reply":"2021-11-06T03:47:48.849070Z"},"trusted":true},"execution_count":286,"outputs":[]},{"cell_type":"markdown","source":"The main matrices is precision, but recall and f1 score is also printed out for each pokemon type. We can see that water type pokemon have much higher precision than fire and grass type, one reason is because water type pokemon have the most number of data thus it have trained better than the other two.","metadata":{}},{"cell_type":"markdown","source":"**Part 2 (25 points):** The following models are widely used for transfer learning because of their performance and architectural innovations:\n\n1. VGG (e.g., VGG16 or VGG19).\n2. GoogLeNet (e.g., InceptionV3).\n3. Residual Network (e.g., ResNet50).\n4. MobileNet (e.g., MobileNetV2)\n\nChoose any **one** of the above models to perform the classification task you did in Part 1. Evaluate the results using the same metrics as in Part 1. Are there any differences? Why or why not?\n\n---","metadata":{}},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nfrom keras.models import Model\n\nmodel = VGG16(include_top=False, input_shape=(256, 256, 3))\nflat1 = Flatten()(model.layers[-1].output)\nclass1 = Dense(64, activation='relu')(flat1)\noutput = Dense(3, activation='softmax')(class1)\nmodel = Model(inputs=model.inputs, outputs=output)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-06T05:01:30.141926Z","iopub.execute_input":"2021-11-06T05:01:30.142207Z","iopub.status.idle":"2021-11-06T05:01:30.544011Z","shell.execute_reply.started":"2021-11-06T05:01:30.142177Z","shell.execute_reply":"2021-11-06T05:01:30.543152Z"},"trusted":true},"execution_count":304,"outputs":[]},{"cell_type":"code","source":"model.compile(loss = 'mean_squared_error', optimizer = \"adam\", metrics = ['accuracy'])\nhistory = model.fit(train, epochs = 5, validation_data = val)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T05:01:43.275655Z","iopub.execute_input":"2021-11-06T05:01:43.275982Z","iopub.status.idle":"2021-11-06T05:22:36.533417Z","shell.execute_reply.started":"2021-11-06T05:01:43.275945Z","shell.execute_reply":"2021-11-06T05:22:36.532624Z"},"trusted":true},"execution_count":305,"outputs":[]},{"cell_type":"code","source":"predict = model.predict(test)\ny_pred = np.argmax(predict, axis=-1)\n\ny_pred_conv = []\nfor i in y_pred:\n  if i == 0:\n    y_pred_conv.append(\"Fire\")\n  elif i == 1:\n    y_pred_conv.append(\"Grass\")\n  elif i == 2:\n    y_pred_conv.append(\"Water\")\n\nprint(classification_report(y_test, y_pred_conv))","metadata":{"execution":{"iopub.status.busy":"2021-11-06T05:25:47.895734Z","iopub.execute_input":"2021-11-06T05:25:47.896031Z","iopub.status.idle":"2021-11-06T05:26:00.405938Z","shell.execute_reply.started":"2021-11-06T05:25:47.895998Z","shell.execute_reply":"2021-11-06T05:26:00.404979Z"},"trusted":true},"execution_count":307,"outputs":[]},{"cell_type":"markdown","source":"The result is worse than the previous one, identifying Water type pokemon is slightly lower and the non of the tests for both fire & grass type pokemon is correct. I'd say there are few reasons behind this:\n\n1. the dataset is two small, there are only ~230 images of pokemon thus the accuracy may not go up.\n2. Test set is too small as well, when splitting up the data set, only 37 images were put into test set.\n3. Overfitting may be one of the cause.\n4. Pokemons of each type do not have obvious features except for their colors(red, green, blue), and even some pokemons' color do not match their actual type.","metadata":{}},{"cell_type":"markdown","source":"**Part 3 (25 points):** Use data augmentation to increase the diversity of your dataset by applying random transformations such as image rotation (you can use any other technique as well). Repeat the process from part 1 with this augmented data. Did you observe any difference in results?\n\n---","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import layers\nresize_rescale_flip_rotation = tf.keras.Sequential([\n  layers.Resizing(128, 128),\n  layers.Rescaling(1./255),\n  layers.RandomFlip(\"horizontal_and_vertical\"),\n  layers.RandomRotation(0.2),\n])","metadata":{"execution":{"iopub.status.busy":"2021-11-06T05:36:55.033456Z","iopub.execute_input":"2021-11-06T05:36:55.034228Z","iopub.status.idle":"2021-11-06T05:36:55.044930Z","shell.execute_reply.started":"2021-11-06T05:36:55.034187Z","shell.execute_reply":"2021-11-06T05:36:55.044307Z"},"trusted":true},"execution_count":312,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Sequential([\n  # Add the preprocessing layers you created earlier.\n  resize_rescale_flip_rotation,\n  layers.Conv2D(16, (3, 3), activation = 'relu'),\n  layers.MaxPooling2D(pool_size = (3, 3)),\n\n  Conv2D(32, (3, 3), activation = 'relu'),\n  MaxPooling2D(pool_size = (3, 3)),\n    \n  Conv2D(64, (3, 3), activation = 'relu'),\n  BatchNormalization(),\n  MaxPooling2D(pool_size = (3, 3)),\n  Dropout(0.3),\n\n  Flatten(),\n  Dense(256, activation = 'relu'),\n  BatchNormalization(),\n  Dropout(0.5),\n  Dense(3, activation = 'softmax')\n])\n\nmodel.compile(loss = 'mean_squared_error', optimizer = \"adam\", metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-11-06T05:37:00.209946Z","iopub.execute_input":"2021-11-06T05:37:00.210801Z","iopub.status.idle":"2021-11-06T05:37:00.238444Z","shell.execute_reply.started":"2021-11-06T05:37:00.210759Z","shell.execute_reply":"2021-11-06T05:37:00.237734Z"},"trusted":true},"execution_count":313,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train, epochs = 20, validation_data = val)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T05:37:12.525971Z","iopub.execute_input":"2021-11-06T05:37:12.526815Z","iopub.status.idle":"2021-11-06T05:37:30.088467Z","shell.execute_reply.started":"2021-11-06T05:37:12.526771Z","shell.execute_reply":"2021-11-06T05:37:30.087555Z"},"trusted":true},"execution_count":314,"outputs":[]},{"cell_type":"code","source":"predict = model.predict(test)\ny_pred = np.argmax(predict, axis=-1)\n\ny_pred_conv = []\nfor i in y_pred:\n  if i == 0:\n    y_pred_conv.append(\"Fire\")\n  elif i == 1:\n    y_pred_conv.append(\"Grass\")\n  elif i == 2:\n    y_pred_conv.append(\"Water\")\n\nprint(classification_report(y_test, y_pred_conv))","metadata":{"execution":{"iopub.status.busy":"2021-11-06T05:37:35.196087Z","iopub.execute_input":"2021-11-06T05:37:35.196406Z","iopub.status.idle":"2021-11-06T05:37:35.579204Z","shell.execute_reply.started":"2021-11-06T05:37:35.196371Z","shell.execute_reply":"2021-11-06T05:37:35.578218Z"},"trusted":true},"execution_count":315,"outputs":[]},{"cell_type":"markdown","source":"Comparing to the result in task 1 the result I have here is much better, I've reduce the size of the image by half and also randomly flipped & rotate the images. All of the tests for water type pokemon is correct and tests for both fire&grass type pokemon have substantially higher precision.","metadata":{}},{"cell_type":"markdown","source":"## Task 2\n\n**Part 1 (15 points): Variational Autoencoder (VAE):** Here is a complete implementation of a VAE in TensorFlow: https://www.tensorflow.org/tutorials/generative/cvae\n\nFollowing these steps try generating images using the same encoder-decoder architecture using a different Image dataset (other than MNIST).\n\n---","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Part 2 (15 points): Generative Adversarial Networks (GANs):** Repeat part 1 (use same dataset) and implement a GAN model to generate high quality synthetic images. You may follow steps outlined here: https://www.tensorflow.org/tutorials/generative/dcgan\n\n---","metadata":{}}]}