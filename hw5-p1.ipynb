{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Homework 5**\n","\n","In your project, you will pick an image dataset to solve a classification task. Provide a link to your dataset.\n","\n","Pokemon Image Dataset: https://www.kaggle.com/vishalsubbiah/pokemon-images-and-types?select=images"]},{"cell_type":"markdown","metadata":{},"source":["## **Task 1**"]},{"cell_type":"markdown","metadata":{},"source":["### **Pre-Setup**\n","\n","I'd like to find out each pokemons primary type(fire, water, grass etc.) based on their image."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2021-11-06T06:04:58.089254Z","iopub.status.busy":"2021-11-06T06:04:58.088949Z","iopub.status.idle":"2021-11-06T06:04:58.094473Z","shell.execute_reply":"2021-11-06T06:04:58.093697Z","shell.execute_reply.started":"2021-11-06T06:04:58.089220Z"},"trusted":true},"outputs":[],"source":["# Imports\n","import pandas as pd\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import matplotlib.gridspec as gridspec\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2021-11-06T06:05:00.149376Z","iopub.status.busy":"2021-11-06T06:05:00.148646Z","iopub.status.idle":"2021-11-06T06:05:00.154630Z","shell.execute_reply":"2021-11-06T06:05:00.153582Z","shell.execute_reply.started":"2021-11-06T06:05:00.149332Z"},"trusted":true},"outputs":[],"source":["from tensorflow import keras as ks\n","from keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, Activation, BatchNormalization"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-11-06T06:05:03.340899Z","iopub.status.busy":"2021-11-06T06:05:03.340586Z","iopub.status.idle":"2021-11-06T06:05:03.360536Z","shell.execute_reply":"2021-11-06T06:05:03.359959Z","shell.execute_reply.started":"2021-11-06T06:05:03.340852Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Type1</th>\n","      <th>Type2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>bulbasaur</td>\n","      <td>Grass</td>\n","      <td>Poison</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ivysaur</td>\n","      <td>Grass</td>\n","      <td>Poison</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>venusaur</td>\n","      <td>Grass</td>\n","      <td>Poison</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>charmander</td>\n","      <td>Fire</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>charmeleon</td>\n","      <td>Fire</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Name  Type1   Type2\n","0   bulbasaur  Grass  Poison\n","1     ivysaur  Grass  Poison\n","2    venusaur  Grass  Poison\n","3  charmander   Fire     NaN\n","4  charmeleon   Fire     NaN"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Get CSV Data\n","df = pd.read_csv(\"pokemon.csv\")\n","df.head(5)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-11-06T06:05:06.385561Z","iopub.status.busy":"2021-11-06T06:05:06.385260Z","iopub.status.idle":"2021-11-06T06:05:06.400070Z","shell.execute_reply":"2021-11-06T06:05:06.399183Z","shell.execute_reply.started":"2021-11-06T06:05:06.385526Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Water    114\n","Grass     78\n","Fire      53\n","Name: Type1, dtype: int64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Select only a few types of pokemon because data are too little\n","selected = [\"Water\", \"Fire\", \"Grass\"]\n","\n","df = df[df['Type1'].isin(selected)]\n","df['Type1'].value_counts()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-11-06T06:05:08.825508Z","iopub.status.busy":"2021-11-06T06:05:08.825211Z","iopub.status.idle":"2021-11-06T06:05:09.839393Z","shell.execute_reply":"2021-11-06T06:05:09.838139Z","shell.execute_reply.started":"2021-11-06T06:05:08.825471Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Type1</th>\n","      <th>Type2</th>\n","      <th>Image</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>bulbasaur</td>\n","      <td>Grass</td>\n","      <td>Poison</td>\n","      <td>bulbasaur.png</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ivysaur</td>\n","      <td>Grass</td>\n","      <td>Poison</td>\n","      <td>ivysaur.png</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>venusaur</td>\n","      <td>Grass</td>\n","      <td>Poison</td>\n","      <td>venusaur.png</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>charmander</td>\n","      <td>Fire</td>\n","      <td>NaN</td>\n","      <td>charmander.png</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>charmeleon</td>\n","      <td>Fire</td>\n","      <td>NaN</td>\n","      <td>charmeleon.png</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Name  Type1   Type2           Image\n","0   bulbasaur  Grass  Poison   bulbasaur.png\n","1     ivysaur  Grass  Poison     ivysaur.png\n","2    venusaur  Grass  Poison    venusaur.png\n","3  charmander   Fire     NaN  charmander.png\n","4  charmeleon   Fire     NaN  charmeleon.png"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["img = os.listdir('./images')\n","for i in img:\n","  name = i.split('.')[0]\n","  df.loc[df['Name'] == name, [\"Image\"]] = i\n","df.head(5)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-11-06T06:05:11.997737Z","iopub.status.busy":"2021-11-06T06:05:11.997464Z","iopub.status.idle":"2021-11-06T06:05:12.017984Z","shell.execute_reply":"2021-11-06T06:05:12.016854Z","shell.execute_reply.started":"2021-11-06T06:05:11.997708Z"},"trusted":true},"outputs":[],"source":["import shutil\n","shutil.rmtree('train/')\n","shutil.rmtree('test/')\n","shutil.rmtree('valid/')\n","\n","os.mkdir('train/')\n","os.mkdir('test/')\n","os.mkdir('valid/')\n","\n","for i in df['Type1'].unique():\n","  os.mkdir('train/'+str(i)+'/')\n","  os.mkdir('test/'+str(i)+'/')\n","  os.mkdir('valid/'+str(i)+'/')"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-11-06T06:05:14.181027Z","iopub.status.busy":"2021-11-06T06:05:14.180745Z","iopub.status.idle":"2021-11-06T06:05:14.189089Z","shell.execute_reply":"2021-11-06T06:05:14.188216Z","shell.execute_reply.started":"2021-11-06T06:05:14.180998Z"},"trusted":true},"outputs":[],"source":["x_train, x_rem, y_train, y_rem = train_test_split(df, df[\"Type1\"], train_size=0.7)\n","x_valid, x_test, y_valid, y_test = train_test_split(x_rem, y_rem, test_size=0.5)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2021-11-06T06:05:16.113619Z","iopub.status.busy":"2021-11-06T06:05:16.113353Z","iopub.status.idle":"2021-11-06T06:05:16.625147Z","shell.execute_reply":"2021-11-06T06:05:16.624242Z","shell.execute_reply.started":"2021-11-06T06:05:16.113591Z"},"trusted":true},"outputs":[],"source":["from shutil import copyfile, copy2\n","for image, types in zip(\"./images/\" + x_train['Image'], y_train):\n","  copy2(image, 'train/' + types)\n","for image, types in zip(\"./images/\" + x_test['Image'], y_test):\n","  copy2(image, 'test/' + types)\n","for image, types in zip(\"./images/\" + x_valid['Image'], y_valid):\n","  copy2(image, 'valid/' + types)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2021-11-06T06:05:18.324670Z","iopub.status.busy":"2021-11-06T06:05:18.324406Z","iopub.status.idle":"2021-11-06T06:05:18.637491Z","shell.execute_reply":"2021-11-06T06:05:18.636553Z","shell.execute_reply.started":"2021-11-06T06:05:18.324643Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 171 images belonging to 3 classes.\n","Found 37 images belonging to 3 classes.\n","Found 37 images belonging to 3 classes.\n"]}],"source":["train = ImageDataGenerator().flow_from_directory('train/')\n","test = ImageDataGenerator().flow_from_directory('test/')\n","val = ImageDataGenerator().flow_from_directory('valid/')"]},{"cell_type":"markdown","metadata":{},"source":["**Part 1 (20 points):**Â This step involves downloading, preparing, and visualizing your dataset. Create a convolutional base using a common pattern: a stack of Conv and MaxPooling layers. Depending on the problem and the dataset you must decide what pattern you want to use (i.e., how many Conv layers and how many pooling layers). Please describe why you chose a particular pattern. Add the final dense layer(s). Compile and train the model. Report the final evaluation and describe the metrics.\n","\n","---\n","\n","For the first Conv2D I choosed 16 filters with size 3, the activation function for each Conv2D is relu. To reduce the spatial dimensions of the output volume a MaxPooling2D is used where the size is 3. For the third layer a dropout of 30% is used to prevent overfitting. After that add the 2nd, 3rd convolutional layer and increase the filter gradually. Lastly flatten into 1 dimension and a dense layer."]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2021-11-06T03:46:24.039984Z","iopub.status.busy":"2021-11-06T03:46:24.039651Z","iopub.status.idle":"2021-11-06T03:46:24.073935Z","shell.execute_reply":"2021-11-06T03:46:24.073132Z","shell.execute_reply.started":"2021-11-06T03:46:24.039952Z"},"trusted":true},"outputs":[],"source":["model = Sequential()\n","\n","model.add(Conv2D(16, (3, 3), activation = 'relu'))\n","model.add(MaxPool2D(pool_size = (3, 3)))\n","\n","model.add(Conv2D(32, (3, 3), activation = 'relu'))\n","model.add(MaxPool2D(pool_size = (3, 3)))\n","\n","model.add(Conv2D(64, (3, 3), activation = 'relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPool2D(pool_size = (3, 3)))\n","model.add(Dropout(0.3))\n","\n","model.add(Flatten())\n","model.add(Dense(256, activation = 'relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(3, activation = 'softmax'))\n","model.compile(loss = 'mean_squared_error', optimizer = \"adam\", metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2021-11-06T03:46:36.314276Z","iopub.status.busy":"2021-11-06T03:46:36.312059Z","iopub.status.idle":"2021-11-06T03:47:04.903461Z","shell.execute_reply":"2021-11-06T03:47:04.902662Z","shell.execute_reply.started":"2021-11-06T03:46:36.314231Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/site-packages/PIL/Image.py:973: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  warnings.warn(\n","2021-11-06 02:10:09.838750: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","6/6 [==============================] - 3s 370ms/step - loss: 0.3063 - accuracy: 0.3860 - val_loss: 0.4370 - val_accuracy: 0.2973\n","Epoch 2/20\n","6/6 [==============================] - 2s 335ms/step - loss: 0.2407 - accuracy: 0.5029 - val_loss: 0.3736 - val_accuracy: 0.3784\n","Epoch 3/20\n","6/6 [==============================] - 2s 353ms/step - loss: 0.2036 - accuracy: 0.5965 - val_loss: 0.3821 - val_accuracy: 0.4054\n","Epoch 4/20\n","6/6 [==============================] - 2s 322ms/step - loss: 0.1829 - accuracy: 0.6608 - val_loss: 0.3371 - val_accuracy: 0.4865\n","Epoch 5/20\n","6/6 [==============================] - 2s 332ms/step - loss: 0.1405 - accuracy: 0.7368 - val_loss: 0.3085 - val_accuracy: 0.5135\n","Epoch 6/20\n","6/6 [==============================] - 2s 325ms/step - loss: 0.1239 - accuracy: 0.7661 - val_loss: 0.2952 - val_accuracy: 0.5405\n","Epoch 7/20\n","6/6 [==============================] - 2s 334ms/step - loss: 0.1096 - accuracy: 0.7836 - val_loss: 0.2609 - val_accuracy: 0.5405\n","Epoch 8/20\n","6/6 [==============================] - 2s 336ms/step - loss: 0.0908 - accuracy: 0.8129 - val_loss: 0.2117 - val_accuracy: 0.6486\n","Epoch 9/20\n","6/6 [==============================] - 2s 349ms/step - loss: 0.0968 - accuracy: 0.8012 - val_loss: 0.2162 - val_accuracy: 0.6216\n","Epoch 10/20\n","6/6 [==============================] - 2s 375ms/step - loss: 0.0833 - accuracy: 0.8480 - val_loss: 0.2872 - val_accuracy: 0.5135\n","Epoch 11/20\n","6/6 [==============================] - 2s 355ms/step - loss: 0.0755 - accuracy: 0.8538 - val_loss: 0.2979 - val_accuracy: 0.5135\n","Epoch 12/20\n","6/6 [==============================] - 2s 364ms/step - loss: 0.0906 - accuracy: 0.8070 - val_loss: 0.2781 - val_accuracy: 0.5135\n","Epoch 13/20\n","6/6 [==============================] - 2s 386ms/step - loss: 0.0749 - accuracy: 0.8538 - val_loss: 0.2771 - val_accuracy: 0.5135\n","Epoch 14/20\n","6/6 [==============================] - 3s 415ms/step - loss: 0.0798 - accuracy: 0.8538 - val_loss: 0.2520 - val_accuracy: 0.5676\n","Epoch 15/20\n","6/6 [==============================] - 2s 341ms/step - loss: 0.0634 - accuracy: 0.8947 - val_loss: 0.2332 - val_accuracy: 0.6216\n","Epoch 16/20\n","6/6 [==============================] - 2s 333ms/step - loss: 0.0546 - accuracy: 0.9064 - val_loss: 0.1990 - val_accuracy: 0.6757\n","Epoch 17/20\n","6/6 [==============================] - 2s 343ms/step - loss: 0.0611 - accuracy: 0.9123 - val_loss: 0.1915 - val_accuracy: 0.6216\n","Epoch 18/20\n","6/6 [==============================] - 2s 352ms/step - loss: 0.0569 - accuracy: 0.8889 - val_loss: 0.1970 - val_accuracy: 0.6216\n","Epoch 19/20\n","6/6 [==============================] - 2s 339ms/step - loss: 0.0421 - accuracy: 0.9357 - val_loss: 0.1902 - val_accuracy: 0.6757\n","Epoch 20/20\n","6/6 [==============================] - 2s 333ms/step - loss: 0.0473 - accuracy: 0.9181 - val_loss: 0.1892 - val_accuracy: 0.6216\n"]}],"source":["history = model.fit(train, epochs = 20, validation_data = val)"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2021-11-06T03:47:48.628641Z","iopub.status.busy":"2021-11-06T03:47:48.628354Z","iopub.status.idle":"2021-11-06T03:47:48.850055Z","shell.execute_reply":"2021-11-06T03:47:48.849070Z","shell.execute_reply.started":"2021-11-06T03:47:48.628612Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","        Fire       0.25      0.44      0.32         9\n","       Grass       0.33      0.23      0.27        13\n","       Water       0.50      0.40      0.44        15\n","\n","    accuracy                           0.35        37\n","   macro avg       0.36      0.36      0.35        37\n","weighted avg       0.38      0.35      0.35        37\n","\n"]}],"source":["from sklearn.metrics import classification_report\n","predict = model.predict(test)\n","y_pred = np.argmax(predict, axis=-1)\n","\n","y_pred_conv = []\n","for i in y_pred:\n","  if i == 0:\n","    y_pred_conv.append(\"Fire\")\n","  elif i == 1:\n","    y_pred_conv.append(\"Grass\")\n","  elif i == 2:\n","    y_pred_conv.append(\"Water\")\n","\n","print(classification_report(y_test, y_pred_conv))"]},{"cell_type":"markdown","metadata":{},"source":["The main matrices is precision, but recall and f1 score is also printed out for each pokemon type. We can see that water type pokemon have much higher precision than fire and grass type, one reason is because water type pokemon have the most number of data thus it have trained better than the other two."]},{"cell_type":"markdown","metadata":{},"source":["**Part 2 (25 points):**Â The following models are widely used for transfer learning because of their performance and architectural innovations:\n","\n","1. VGG (e.g., VGG16 or VGG19).\n","2. GoogLeNet (e.g., InceptionV3).\n","3. Residual Network (e.g., ResNet50).\n","4. MobileNet (e.g., MobileNetV2)\n","\n","Choose anyÂ **one**Â of the above models to perform the classification task you did in Part 1. Evaluate the results using the same metrics as in Part 1. Are there any differences? Why or why not?\n","\n","---"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2021-11-06T05:01:30.142207Z","iopub.status.busy":"2021-11-06T05:01:30.141926Z","iopub.status.idle":"2021-11-06T05:01:30.544011Z","shell.execute_reply":"2021-11-06T05:01:30.543152Z","shell.execute_reply.started":"2021-11-06T05:01:30.142177Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 2s 0us/step\n","58900480/58889256 [==============================] - 2s 0us/step\n","Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 32768)             0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 64)                2097216   \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 3)                 195       \n","=================================================================\n","Total params: 16,812,099\n","Trainable params: 16,812,099\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["from keras.applications.vgg16 import VGG16\n","from keras.models import Model\n","\n","model = VGG16(include_top=False, input_shape=(256, 256, 3))\n","flat1 = Flatten()(model.layers[-1].output)\n","class1 = Dense(64, activation='relu')(flat1)\n","output = Dense(3, activation='softmax')(class1)\n","model = Model(inputs=model.inputs, outputs=output)\n","model.summary()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2021-11-06T05:01:43.275982Z","iopub.status.busy":"2021-11-06T05:01:43.275655Z","iopub.status.idle":"2021-11-06T05:22:36.533417Z","shell.execute_reply":"2021-11-06T05:22:36.532624Z","shell.execute_reply.started":"2021-11-06T05:01:43.275945Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/site-packages/PIL/Image.py:973: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","6/6 [==============================] - 84s 14s/step - loss: 0.3829 - accuracy: 0.4211 - val_loss: 0.3243 - val_accuracy: 0.5135\n","Epoch 2/5\n","6/6 [==============================] - 80s 15s/step - loss: 0.3548 - accuracy: 0.4678 - val_loss: 0.3243 - val_accuracy: 0.5135\n","Epoch 3/5\n","6/6 [==============================] - 80s 13s/step - loss: 0.3548 - accuracy: 0.4678 - val_loss: 0.3243 - val_accuracy: 0.5135\n","Epoch 4/5\n","6/6 [==============================] - 81s 13s/step - loss: 0.3548 - accuracy: 0.4678 - val_loss: 0.3243 - val_accuracy: 0.5135\n","Epoch 5/5\n","6/6 [==============================] - 81s 13s/step - loss: 0.3548 - accuracy: 0.4678 - val_loss: 0.3243 - val_accuracy: 0.5135\n"]}],"source":["model.compile(loss = 'mean_squared_error', optimizer = \"adam\", metrics = ['accuracy'])\n","history = model.fit(train, epochs = 5, validation_data = val)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2021-11-06T05:25:47.896031Z","iopub.status.busy":"2021-11-06T05:25:47.895734Z","iopub.status.idle":"2021-11-06T05:26:00.405938Z","shell.execute_reply":"2021-11-06T05:26:00.404979Z","shell.execute_reply.started":"2021-11-06T05:25:47.895998Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","        Fire       0.00      0.00      0.00         9\n","       Grass       0.00      0.00      0.00        13\n","       Water       0.41      1.00      0.58        15\n","\n","    accuracy                           0.41        37\n","   macro avg       0.14      0.33      0.19        37\n","weighted avg       0.16      0.41      0.23        37\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["predict = model.predict(test)\n","y_pred = np.argmax(predict, axis=-1)\n","\n","y_pred_conv = []\n","for i in y_pred:\n","  if i == 0:\n","    y_pred_conv.append(\"Fire\")\n","  elif i == 1:\n","    y_pred_conv.append(\"Grass\")\n","  elif i == 2:\n","    y_pred_conv.append(\"Water\")\n","\n","print(classification_report(y_test, y_pred_conv))"]},{"cell_type":"markdown","metadata":{},"source":["The result is worse than the previous one, identifying Water type pokemon is slightly lower and the non of the tests for both fire & grass type pokemon is correct. I'd say there are few reasons behind this:\n","\n","1. the dataset is two small, there are only ~230 images of pokemon thus the accuracy may not go up.\n","2. Test set is too small as well, when splitting up the data set, only 37 images were put into test set.\n","3. Overfitting may be one of the cause.\n","4. Pokemons of each type do not have obvious features except for their colors(red, green, blue), and even some pokemons' color do not match their actual type."]},{"cell_type":"markdown","metadata":{},"source":["**Part 3 (25 points):**Â Use data augmentation to increase the diversity of your dataset by applying random transformations such as image rotation (you can use any other technique as well). Repeat the process from part 1 with this augmented data. Did you observe any difference in results?\n","\n","---"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2021-11-06T05:36:55.034228Z","iopub.status.busy":"2021-11-06T05:36:55.033456Z","iopub.status.idle":"2021-11-06T05:36:55.044930Z","shell.execute_reply":"2021-11-06T05:36:55.044307Z","shell.execute_reply.started":"2021-11-06T05:36:55.034187Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras import layers\n","resize_rescale_flip_rotation = tf.keras.Sequential([\n","  layers.Resizing(128, 128),\n","  layers.Rescaling(1./255),\n","  layers.RandomFlip(\"horizontal_and_vertical\"),\n","  layers.RandomRotation(0.2),\n","])"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2021-11-06T05:37:00.210801Z","iopub.status.busy":"2021-11-06T05:37:00.209946Z","iopub.status.idle":"2021-11-06T05:37:00.238444Z","shell.execute_reply":"2021-11-06T05:37:00.237734Z","shell.execute_reply.started":"2021-11-06T05:37:00.210759Z"},"trusted":true},"outputs":[],"source":["model = tf.keras.Sequential([\n","  # Add the preprocessing layers you created earlier.\n","  resize_rescale_flip_rotation,\n","  layers.Conv2D(16, (3, 3), activation = 'relu'),\n","  layers.MaxPool2D(pool_size = (3, 3)),\n","\n","  Conv2D(32, (3, 3), activation = 'relu'),\n","  MaxPool2D(pool_size = (3, 3)),\n","    \n","  Conv2D(64, (3, 3), activation = 'relu'),\n","  BatchNormalization(),\n","  MaxPool2D(pool_size = (3, 3)),\n","  Dropout(0.3),\n","\n","  Flatten(),\n","  Dense(256, activation = 'relu'),\n","  BatchNormalization(),\n","  Dropout(0.5),\n","  Dense(3, activation = 'softmax')\n","])\n","\n","model.compile(loss = 'mean_squared_error', optimizer = \"adam\", metrics = ['accuracy'])"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2021-11-06T05:37:12.526815Z","iopub.status.busy":"2021-11-06T05:37:12.525971Z","iopub.status.idle":"2021-11-06T05:37:30.088467Z","shell.execute_reply":"2021-11-06T05:37:30.087555Z","shell.execute_reply.started":"2021-11-06T05:37:12.526771Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","1/6 [====>.........................] - ETA: 0s - loss: 0.0574 - accuracy: 0.9091"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/site-packages/PIL/Image.py:973: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["6/6 [==============================] - 1s 153ms/step - loss: 0.1009 - accuracy: 0.8129 - val_loss: 0.2850 - val_accuracy: 0.4054\n","Epoch 2/20\n","6/6 [==============================] - 1s 128ms/step - loss: 0.0785 - accuracy: 0.8480 - val_loss: 0.1992 - val_accuracy: 0.5676\n","Epoch 3/20\n","6/6 [==============================] - 1s 122ms/step - loss: 0.0787 - accuracy: 0.8538 - val_loss: 0.1635 - val_accuracy: 0.6757\n","Epoch 4/20\n","6/6 [==============================] - 1s 118ms/step - loss: 0.0761 - accuracy: 0.8713 - val_loss: 0.1858 - val_accuracy: 0.5946\n","Epoch 5/20\n","6/6 [==============================] - 1s 123ms/step - loss: 0.0737 - accuracy: 0.8596 - val_loss: 0.1622 - val_accuracy: 0.6486\n","Epoch 6/20\n","6/6 [==============================] - 1s 120ms/step - loss: 0.0768 - accuracy: 0.8655 - val_loss: 0.1693 - val_accuracy: 0.5946\n","Epoch 7/20\n","6/6 [==============================] - 1s 135ms/step - loss: 0.0900 - accuracy: 0.8363 - val_loss: 0.1154 - val_accuracy: 0.7838\n","Epoch 8/20\n","6/6 [==============================] - 1s 137ms/step - loss: 0.0743 - accuracy: 0.8713 - val_loss: 0.0973 - val_accuracy: 0.8108\n","Epoch 9/20\n","6/6 [==============================] - 1s 118ms/step - loss: 0.0801 - accuracy: 0.8538 - val_loss: 0.0876 - val_accuracy: 0.8378\n","Epoch 10/20\n","6/6 [==============================] - 1s 118ms/step - loss: 0.0684 - accuracy: 0.8655 - val_loss: 0.0812 - val_accuracy: 0.8108\n","Epoch 11/20\n","6/6 [==============================] - 1s 122ms/step - loss: 0.0775 - accuracy: 0.8596 - val_loss: 0.0785 - val_accuracy: 0.8108\n","Epoch 12/20\n","6/6 [==============================] - 1s 138ms/step - loss: 0.0867 - accuracy: 0.8421 - val_loss: 0.0757 - val_accuracy: 0.8378\n","Epoch 13/20\n","6/6 [==============================] - 1s 121ms/step - loss: 0.0674 - accuracy: 0.8713 - val_loss: 0.0744 - val_accuracy: 0.8649\n","Epoch 14/20\n","6/6 [==============================] - 1s 133ms/step - loss: 0.0779 - accuracy: 0.8596 - val_loss: 0.0995 - val_accuracy: 0.7568\n","Epoch 15/20\n","6/6 [==============================] - 1s 122ms/step - loss: 0.0716 - accuracy: 0.8655 - val_loss: 0.1141 - val_accuracy: 0.7297\n","Epoch 16/20\n","6/6 [==============================] - 1s 118ms/step - loss: 0.0741 - accuracy: 0.8655 - val_loss: 0.1323 - val_accuracy: 0.7027\n","Epoch 17/20\n","6/6 [==============================] - 1s 124ms/step - loss: 0.0801 - accuracy: 0.8538 - val_loss: 0.0992 - val_accuracy: 0.7838\n","Epoch 18/20\n","6/6 [==============================] - 1s 137ms/step - loss: 0.0654 - accuracy: 0.8772 - val_loss: 0.1324 - val_accuracy: 0.7027\n","Epoch 19/20\n","6/6 [==============================] - 1s 121ms/step - loss: 0.0739 - accuracy: 0.8596 - val_loss: 0.1471 - val_accuracy: 0.7027\n","Epoch 20/20\n","6/6 [==============================] - 1s 122ms/step - loss: 0.0669 - accuracy: 0.8830 - val_loss: 0.1592 - val_accuracy: 0.6486\n"]}],"source":["history = model.fit(train, epochs = 20, validation_data = val)"]},{"cell_type":"code","execution_count":97,"metadata":{"execution":{"iopub.execute_input":"2021-11-06T05:37:35.196406Z","iopub.status.busy":"2021-11-06T05:37:35.196087Z","iopub.status.idle":"2021-11-06T05:37:35.579204Z","shell.execute_reply":"2021-11-06T05:37:35.578218Z","shell.execute_reply.started":"2021-11-06T05:37:35.196371Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","        Fire       0.33      0.22      0.27         9\n","       Grass       0.50      0.85      0.63        13\n","       Water       0.78      0.47      0.58        15\n","\n","    accuracy                           0.54        37\n","   macro avg       0.54      0.51      0.49        37\n","weighted avg       0.57      0.54      0.52        37\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/site-packages/PIL/Image.py:973: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n","  warnings.warn(\n"]}],"source":["predict = model.predict(test)\n","y_pred = np.argmax(predict, axis=-1)\n","\n","y_pred_conv = []\n","for i in y_pred:\n","  if i == 0:\n","    y_pred_conv.append(\"Fire\")\n","  elif i == 1:\n","    y_pred_conv.append(\"Grass\")\n","  elif i == 2:\n","    y_pred_conv.append(\"Water\")\n","\n","print(classification_report(y_test, y_pred_conv))"]},{"cell_type":"markdown","metadata":{},"source":["Comparing to the result in task 1 the result I have here is much better, I've reduce the size of the image by half and also randomly flipped & rotate the images.\n","Most of the tests for water type pokemon is correct and tests for both fire&grass type pokemon have substantially higher precision."]}],"metadata":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"},"kernelspec":{"display_name":"Python 3.9.7 64-bit","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":4}
